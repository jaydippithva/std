{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEM 1</th>\n",
       "      <th>SEM 2</th>\n",
       "      <th>SEM 3</th>\n",
       "      <th>SEM 4</th>\n",
       "      <th>SEM 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.60</td>\n",
       "      <td>7.60</td>\n",
       "      <td>6.90</td>\n",
       "      <td>7.22</td>\n",
       "      <td>7.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.77</td>\n",
       "      <td>7.22</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.90</td>\n",
       "      <td>7.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.90</td>\n",
       "      <td>6.00</td>\n",
       "      <td>7.12</td>\n",
       "      <td>7.54</td>\n",
       "      <td>6.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.50</td>\n",
       "      <td>6.60</td>\n",
       "      <td>6.70</td>\n",
       "      <td>6.50</td>\n",
       "      <td>6.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.20</td>\n",
       "      <td>6.00</td>\n",
       "      <td>7.21</td>\n",
       "      <td>7.70</td>\n",
       "      <td>7.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEM 1  SEM 2  SEM 3  SEM 4  SEM 5\n",
       "0   6.60   7.60   6.90   7.22   7.08\n",
       "1   7.77   7.22   7.00   7.90   7.47\n",
       "2   6.90   6.00   7.12   7.54   6.89\n",
       "3   5.50   6.60   6.70   6.50   6.33\n",
       "4   7.20   6.00   7.21   7.70   7.03"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_excel(\"student.xls\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(grade):\n",
    "    if grade>=8.0:\n",
    "        return 'excellent'\n",
    "    elif grade >= 6.0:\n",
    "        return 'average'\n",
    "    else:\n",
    "        return 'improvement'\n",
    "    \n",
    "x = df[['SEM 1','SEM 2','SEM 3','SEM 4']]\n",
    "y=df['SEM 5']\n",
    "y =y.apply(convert)\n",
    "\n",
    "#print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfr = RandomForestClassifier(n_estimators=10,bootstrap=True)\n",
    "rfr.fit(x_train,y_train)\n",
    "y_pred = rfr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print('Accuracy Score:', metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Actual    Predicted\n",
      "288  improvement  improvement\n",
      "283  improvement  improvement\n",
      "327  improvement  improvement\n",
      "145    excellent    excellent\n",
      "55       average      average\n",
      "93       average      average\n",
      "341  improvement  improvement\n",
      "82       average      average\n",
      "366  improvement  improvement\n",
      "148    excellent    excellent\n",
      "358  improvement  improvement\n",
      "209    excellent    excellent\n",
      "33     excellent    excellent\n",
      "90       average      average\n",
      "367  improvement  improvement\n",
      "314  improvement  improvement\n",
      "334  improvement  improvement\n",
      "113    excellent    excellent\n",
      "320  improvement  improvement\n",
      "108      average      average\n"
     ]
    }
   ],
   "source": [
    "comparison = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "print(comparison.head(20))  # show first 20 comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[48  1  0]\n",
      " [ 1 28  0]\n",
      " [ 1  0 35]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       0.96      0.98      0.97        49\n",
      "  versicolor       0.97      0.97      0.97        29\n",
      "   virginica       1.00      0.97      0.99        36\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.98      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cr=classification_report(y_test, y_pred, target_names=iris.target_names)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pridicted value is\n",
      "['excellent']\n"
     ]
    }
   ],
   "source": [
    "print(\"pridicted value is\")\n",
    "print(rfr.predict([[1.5,8.4,2.3,8.2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.13452755 0.29853896 0.15733039 0.4096031 ]\n"
     ]
    }
   ],
   "source": [
    "print(rfr.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree 1 prediction: 2.0\n",
      "Tree 2 prediction: 2.0\n",
      "Tree 3 prediction: 2.0\n",
      "Tree 4 prediction: 2.0\n",
      "Tree 5 prediction: 2.0\n",
      "Tree 6 prediction: 2.0\n",
      "Tree 7 prediction: 2.0\n",
      "Tree 8 prediction: 2.0\n",
      "Tree 9 prediction: 2.0\n",
      "Tree 10 prediction: 2.0\n",
      "Random Forest final prediction: improvement\n"
     ]
    }
   ],
   "source": [
    "# Pick one sample\n",
    "sample = x_test.to_numpy()\n",
    "\n",
    "# Loop through each tree and print prediction\n",
    "for i, tree in enumerate(rfr.estimators_):\n",
    "    pred = tree.predict(sample)[0]\n",
    "    print(f\"Tree {i+1} prediction: {pred}\")\n",
    "\n",
    "# Final Random Forest prediction\n",
    "print(\"Random Forest final prediction:\", rfr.predict(sample)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
